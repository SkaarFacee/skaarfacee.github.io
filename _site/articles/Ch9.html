<!DOCTYPE html>



<html lang="en" class="h-100">

<head>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="I turn coffee into code, use tabs over spaces and never broke production.">

  <title>Personal Website</title>
  <link rel="shortcut icon" type="image/x-icon" href="/assets/favicon.ico">

  <!-- Font Awesome CDN -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css">

  <!-- Bootstrap CSS CDN -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">

  <!-- Animate CSS CDN -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.css" type="text/css"/>
  
  <!-- Custom CSS -->
  <link rel="stylesheet" href="/assets/css/style.css" type="text/css">

</head>


<body class="d-flex flex-column h-100">

  <main class="flex-shrink-0 container mt-5">
  <nav class="navbar navbar-expand-lg navbar-light">

  <a class="navbar-brand" href="/"><h5><b>Personal Website</b></h5></a>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
    <div class="navbar-nav ml-auto">
      
      
        
      
        
      
        
          
        
      
        
          
            <a class="nav-item nav-link " href=" /projects/ ">Projects</a>
          
        
      
        
          
            <a class="nav-item nav-link  active " href=" /articles/ ">Blog</a>
          
        
      
        
          
        
      
        
          
            <a class="nav-item nav-link " href=" /about/ ">About</a>
          
        
      
        
          
            <a class="nav-item nav-link " href=" https://github.com/skaarfacee/ "><i class="fab fa-1x fa-github"></i></a>
          
        
      
    </div>
  </div>

</nav>
  <div class="col-lg-10 mx-auto mt-5 article">
  <h1><b>Unsupervised Learning Algorithms</b></h1>

<p class="article-metadata text-muted">
  26 May 2021 -  
  <b>
  
  
    5 mins read time
  
  </b>

  <br>

  
    Tags: 
    
    <a class="text-decoration-none no-underline" href="/articles/tags#hands-on-machine-learning2">
      <span class="tag badge badge-pill text-primary border border-primary">Hands-On Machine Learning2</span>
    </a>
    
  

</p>

<p>Although most applications of ML are based on supervised learning, most of the data available in the real world is unlabeled . The most important unsupervised learning algorithms fall into 3 main categories :</p>
<ul>
  <li>Clustering</li>
  <li>Anomaly Detection</li>
  <li>Density Estimation</li>
</ul>

<h1 id="clustering">Clustering</h1>
<p>Clustering is the task of identifying similar instances and assigning them to clusters. Just like classification, each instance gets assigned to a particular group, however their task is unsupervised. Clustering used in a variety of applications such as:</p>
<ul>
  <li><strong>Customer Segmentation</strong></li>
  <li><strong>Data Analysis</strong>: At times it is best to know different clusters in the data.</li>
  <li><strong>Dimensionality Reduction</strong>: Once a dataset is clustered it can be used to measure each instance’s affinity with each cluster. If there is a ‘K’ clusters , it can be converted to k-dimensions</li>
  <li><strong>Anomaly Detection</strong>: Any instance that has a low affinity is more likely to be an anomaly</li>
  <li><strong>Semi Supervised Learning</strong>:You can always perform clustering and label all elements in the same class together</li>
  <li><strong>Search Engines</strong>: Some search engines allow you to search for images based on reference images. This falls under the same category.
    <h1 id="k-means">K means</h1>
    <p>After performing k-means you find out that the labels are inaccurate towards the boundaries. This is because k-means is only considered with the instance distance from the centroid of the cluster. Assigning each instance to a cluster is called <em>hard clustering</em>. While giving each instance a score per each cluster is called <em>soft clustering</em>.</p>
    <h2 id="centroid-initialization-methods">Centroid Initialization Methods</h2>
    <p>If you happen to know where the centroids are located ( done by using any other algorithm) you can use its values and set it as a hyperparameter in <code class="language-plaintext highlighter-rouge">sklearn</code>.
       Another solution is to run the algorithm multiple times and keep the best solution. This is controlled by the <code class="language-plaintext highlighter-rouge">n_init</code> hyperparameter and by default it’s value is set to <code class="language-plaintext highlighter-rouge">10</code>. This means without being specified the algorithm runs 10 times, keeping only the best solution. The performance measure used to pick the best solution is called <strong>inertia</strong>.
       Inertia is basically the mean squared distance between each instance and the closest centroid. The k-means algorithm runs <code class="language-plaintext highlighter-rouge">n_init</code> times and keeps the model with the lowest inertia. An improvement to the k-means algorithm is the k-means++ algorithm. In this algorithm they choose the starting centroids that are distant from each other. This helps in converging to a suboptimal solution. The additional step to initialize the centroids is well worth it as it can help in reducing the number of times the algorithm needs to be run.
The steps to initialize the centroids using K-Means++ are:</p>
    <blockquote>
      <ol>
        <li>The first cluster is chosen uniformly at random from the data points that we want to cluster. This is similar to what we do in K-Means, but instead of randomly picking all the centroids, we just pick one centroid here</li>
        <li>Next, we compute the distance (D(x)) of each data point (x) from the cluster center that has already been chosen</li>
        <li>Then, choose the new cluster center from the data points with the probability of x being proportional to (D(x))2</li>
        <li>We then repeat steps 2 and 3 until <em>k</em> clusters have been chosen</li>
      </ol>
    </blockquote>
  </li>
</ul>

<h1 id="finding-the-optimal-number-of-clusters">Finding the optimal number of clusters</h1>
<p>Inertia is not a good performance metric when we try to choose the value of ‘k’ since it keeps getting lower as we increase the value of ‘k’.  A technique that is best used to find the number of ‘k’ clusters is to use the silhouette coefficient. The silhouette coefficient is given by</p>

<p align="center">
<img src="https://editor.analyticsvidhya.com/uploads/59928Untitled.png" />
</p>

<p>The silhouette coefficient can vary between -1 and 1. A value of 1 means the instance is very well in its own cluster and far from the other clusters. A coefficient value of 0 means the instance is located close to the boundary.  A value of -1 means that it has been assigned to the wrong cluster. In sklearn to find the silhouette scores you can always use  <code class="language-plaintext highlighter-rouge">silhouette_score()</code>. Silhouette diagrams are a visual representation of this and are always useful.</p>
<h1 id="limits-of-k-means">Limits of K-means</h1>
<p>Despite the fact that this algorithm is fast and scalable, this method is far from accurate as the due to the fact that this has to be run multiple times and the process to find the value of ‘k’ is also quite tedious. At the same time K-means do not tend to behave properly if the clusters are of varying sizes.</p>

<hr />
<h4 id="clustering-can-be-used-as-an-efficient-approach-to-dimensionality-reduction-in-particular-as-a-pre-processing-step-before-a-supervised-algorithm">Clustering can be used as an efficient approach to dimensionality reduction, in particular as a pre-processing step before a supervised algorithm</h4>

<hr />
<h1 id="dbscan">DBSCAN</h1>
<p>This algorithm defines clusters as continuous regions of density. The algorithm is as follows:</p>
<blockquote>
  <ol>
    <li>Find the points in the ε (eps) neighborhood of every point, and identify the core points with more than minPts neighbors.</li>
    <li>Find the connected components “Connected component (graph theory)”) of <em>core</em> points on the neighbor graph, ignoring all non-core points.</li>
    <li>Assign each non-core point to a nearby cluster if the cluster is an ε (eps) neighbor, otherwise assign it to noise.</li>
  </ol>
</blockquote>

<p>DBSCAN does not have a <code class="language-plaintext highlighter-rouge">predict</code>method but only a <code class="language-plaintext highlighter-rouge">fit_predict</code> method</p>
<h1 id="other-clustering-algorithms">Other Clustering Algorithms</h1>
<h2 id="agglomerative-clustering">Agglomerative Clustering</h2>
<p>A hierarchy of clusters is built from bottom up. At each iteration, this algorithm connects the nearest pair of clusters</p>
<h2 id="birch">Birch</h2>
<p>Built for large datasets and faster than K-means as long as the features are less than 20</p>
<h2 id="mean-shift">Mean Shift</h2>
<p>Algorithm starts by placing a circle centered on each instance. For each circle it computes the mean of all instances located in it and then shifts the circle so it is centered around the mean. It keeps iterating until the circle no longer moves. The algorithm shifts circles into a direction of high density. Finally all instances whose circle have settled is the place that forms a cluster. This is not suited for large datasets and it tends to cheap clusters into pieces if they have internal density variations</p>
<h2 id="spectral-clustering">Spectral Clustering</h2>
<p>Algorithm take a similarity matrix between instances creates a low dimensional embedding from it. If then uses another clustering algorithm in this low dimensional space</p>



<footer>
  This Article is <b>open source</b>. Noticed a typo? </br>
  Or something unclear? Send a PR :)
</footer>
</div>
  </main>

  <footer class="mt-auto py-3 text-center">

  <small class="text-muted mb-2">
    <i class="fas fa-code"></i> with <i class="fas fa-heart"></i>
    <!--by <strong>Aditya Anil</strong>-->
  </small>

  <div class="container-fluid justify-content-center">

  

  

    
    
      

    
    
      

    
    

    
    <a class="social mx-1"  href="mailto:aditya8anil@gmail.com"
       style="color: #6c757d"
       onMouseOver="this.style.color='#db4437'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fas fa-envelope fa-1x"></i>
    </a>
  
  

    
    

    
    <a class="social mx-1"  href="https://www.facebook.com/aditya8anil"
       style="color: #6c757d"
       onMouseOver="this.style.color='#3b5998'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-facebook fa-1x"></i>
    </a>
  
  

    
    

    
    <a class="social mx-1"  href="https://www.github.com/skaarfacee"
       style="color: #6c757d"
       onMouseOver="this.style.color='#333333'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-github fa-1x"></i>
    </a>
  
  

    
    

    
    <a class="social mx-1"  href="https://www.instagram.com/aaaddii__10"
       style="color: #6c757d"
       onMouseOver="this.style.color='#405de6'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-instagram fa-1x"></i>
    </a>
  
  

    
    

    
    <a class="social mx-1"  href="https://www.linkedin.com/in/aditya-anil"
       style="color: #6c757d"
       onMouseOver="this.style.color='#007bb5'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-linkedin-in fa-1x"></i>
    </a>
  
  

    
    

    
    <a class="social mx-1"  href="https://open.spotify.com/user/31oblpch73x3nnnrekndxanrtqvm"
       style="color: #6c757d"
       onMouseOver="this.style.color='#1db954'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-spotify fa-1x"></i>
    </a>
  
  

    
    

    
    <a class="social mx-1"  href="https://www.twitter.com/AdityaAnil19"
       style="color: #6c757d"
       onMouseOver="this.style.color='#1da1f2'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-twitter fa-1x"></i>
    </a>
  
  

</div>

</footer>
  <!-- GitHub Buttons -->
<script async defer src="https://buttons.github.io/buttons.js"></script>

<!-- jQuery CDN -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<!-- Popper.js CDN -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js"></script>

<!-- Bootstrap JS CDN -->
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>

<!-- wow.js CDN & Activation -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/wow/1.1.2/wow.js"></script>
<script> new WOW().init(); </script>

<!-- Card Animation jQuery -->
<script src="/assets/js/card-animation.js"></script>

<!-- Initialize all tooltips -->
<script>
$(function () {
    $('[data-toggle="tooltip"]').tooltip()
})
</script>

</body>

</html>